<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Nil Biescas</title>
    <meta name="author" content="Nil Biescas">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">

    <!-- Keep only page-level tweaks here. The hover box is fixed below. -->
    <style>
      p { text-align: justify; }
      .name { text-align: center !important; }
      .papertitle { font-weight: bold; }
    </style>
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr style="padding:0px">
          <td style="padding:0px">

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr style="padding:0px">
                  <td style="padding:2.5%;width:63%;vertical-align:middle">
                    <p class="name">Nil Biescas</p>
                    <p>
                    I am currently looking for Summer 2026 internships in physical AI, generative AI, and multimodal learning.
                    </p>
                    <p>
                      I am a first-year Master’s student in Data Science at
                      <a href="https://www.epfl.ch/en/">École Polytechnique Fédérale de Lausanne (EPFL)</a>,
                      and I previously graduated in the top three of Spain’s first Artificial Intelligence cohort at the
                      <a href="https://www.uab.cat/web/universitat-autonoma-de-barcelona-1345467954774.html">Universitat Autònoma de Barcelona (UAB)</a>.
                      I completed my final bachelor semester at the
                      <a href="https://www.tum.de/">Technical University of Munich (TUM)</a>,
                      where I conducted my thesis under the supervision of
                      <a href="https://cvg.cit.tum.de/members/cremers">Daniel Cremers</a>,
                      <a href="https://fwmb.github.io/">Felix Wimbauer</a>,
                      and <a href="https://dominikmuhle.github.io/">Dominik Muhle</a>.
                      I have nearly two years of research experience at one of the country’s leading AI centers, with publications at international venues including ECCV and ICDAR.
                      I am fluent in English, Catalan, and Spanish, and I am deeply motivated to advance AI research and its real-world impact.
                    </p>
                    <p>At CVC I've worked on Document Understanding using graph neural networks.</p>
                    <p style="text-align:center">
                      <a href="mailto:nilbiescas3@gmail.com">Email</a> /
                      <a href="data/cv_nil_2024_07.pdf">CV</a> /
                      <a href="https://scholar.google.com/citations?hl=en&user=gtHrYbUAAAAJ">Scholar</a> /
                      <a href="https://twitter.com/biescss">Twitter</a> /
                      <a href="https://github.com/NilBiescas">Github</a>
                    </p>
                  </td>
                  <td style="padding:2.5%;width:37%;max-width:37%">
                    <a href="images/Nil_cvc.png">
                      <img style="width:100%;max-width:100%;object-fit:cover;border-radius:50%;" alt="profile photo" src="images/Nil_cvc.png" class="hoverZoomLink">
                    </a>
                  </td>
                </tr>
              </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr>
                  <td style="padding:16px;width:100%;vertical-align:middle">
                    <h2>Research</h2>
                    <p>I'm interested in computer vision, deep learning, generative AI, and image processing.</p>
                  </td>
                </tr>
              </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <!-- Teleoperation -->
                <tr bgcolor="#f0f0f0">
                  <td style="padding:16px;width:20%;vertical-align:middle">
                    <div class="one has-hover">
                      <div class="two">
                        <video muted loop playsinline preload="metadata">
                          <source src="data/videos/teleop.mp4" type="video/mp4">
                        </video>
                      </div>
                      <img src="data/images/position_control.png" alt="Telop">
                    </div>
                  </td>
                  <td style="padding:8px;width:80%;vertical-align:middle">
                    <a href="https://nilbiescas.github.io/HapticTeleoperation/" target="_blank">
                      <span class="papertitle">Haptic Teleoperation and Learning from Demonstration with the Franka Robotic Arm</span>
                    </a>
                    <br>
                    <strong>Nil Biescas</strong>
                    <br>
                    <em>Manuscript</em>, 2025
                    <br>
                    
                    <p></p>
                    <p>In this thesis we expand AnyCam, a self supervised method for predicting camera poses for dynamic videos, to predict point clouds of dynamic scenes.</p>
                  </td>
                </tr>

                <!-- AnyCam-3D -->
                <tr bgcolor="#f0f0f0">
                  <td style="padding:16px;width:20%;vertical-align:middle">
                    <div class="one has-hover">
                      <div class="two">
                        <video muted loop playsinline preload="metadata">
                          <source src="data/Recording 2025-09-03 003520.mp4" type="video/mp4">
                        </video>
                      </div>
                      <img src="data/image (1).png" alt="AnyCam-3D thumbnail">
                    </div>
                  </td>
                  <td style="padding:8px;width:80%;vertical-align:middle">
                    <a href="data/ICDAR2025_Layout_Meet_Language.pdf" target="_blank">
                      <span class="papertitle">AnyCam-3D: Extending AnyCam for Dense 3D Geometry Reconstruction in Dynamic, Uncalibrated Videos</span>
                    </a>
                    <br>
                    <strong>Nil Biescas</strong>
                    <br>
                    <em>Manuscript</em>, 2025
                    <br>
                    <a href="data/TUM_Thesis_for_Informatics.pdf" target="_blank">Download PDF</a>
                    <p></p>
                    <p>In this thesis we expand AnyCam, a self supervised method for predicting camera poses for dynamic videos, to predict point clouds of dynamic scenes.</p>
                  </td>
                </tr>

                <!-- Layout Meets Language -->
                <!-- You had a PNG inside a video tag. Keep it as an image unless you have a real mp4. -->
                <tr bgcolor="#f0f0f0">
                  <td style="padding:16px;width:20%;vertical-align:middle">
                    <div class="one">
                      <img src="data/Large Language Model (LLM)lm.png" alt="Layout Meets Language thumbnail">
                    </div>
                  </td>
                  <td style="padding:8px;width:80%;vertical-align:middle">
                    <a href="data/ICDAR2025_Layout_Meet_Language.pdf" target="_blank">
                      <span class="papertitle">Where Layout Meets Language: Lightweight Spatial Enhancement to Large Language Models for Document Understanding</span>
                    </a>
                    <br>
                    <strong>Nil Biescas</strong>
                    <br>
                    <em>Manuscript</em>, 2025
                    <br>
                    <a href="data/ICDAR2025_Layout_Meet_Language.pdf" target="_blank">Download PDF</a>
                    <p></p>
                    <p>A paper exploring the interaction between visual document layout and natural language processing.</p>
                  </td>
                </tr>

                <!-- LayeredDoc -->
                <!-- You had a GIF inside a video tag. Just show the GIF as an image. -->
                <tr>
                  <td style="padding:16px;width:20%;vertical-align:middle">
                    <div class="one">
                      <img src="images/layeredDoc.gif" alt="LayeredDoc preview">
                    </div>
                  </td>
                  <td style="padding:8px;width:80%;vertical-align:middle">
                    <a href="https://layereddoc.github.io/">
                      <span class="papertitle">LayeredDoc: Domain Adaptive Document Restoration with a Layer Separation Approach</span>
                    </a>
                    <br>
                    <strong>Nil Biescas</strong>,
                    <a href="https://mpilligua.github.io/">Maria Pilligua</a>,
                    <a href="https://www.jvazquez-corral.net/">Javier Vazquez-Corral</a>,
                    <a href="https://scholar.google.es/citations?user=92pWl-AAAAAJ&hl=es">Josep Lladós</a>,
                    <a href="https://scholar.google.es/citations?user=ChmX8ogAAAAJ&hl=en">Ernest Valveny</a>,
                    <a href="https://scholar.google.co.in/citations?user=J-VlCNYAAAAJ&hl=en">Sanket Biswas</a>
                    <br>
                    <em>ECCV WiCV, ICDAR</em>, 2024
                    <br>
                    <a href="https://layereddoc.github.io/">project page</a> /
                    <a href="https://arxiv.org/abs/2406.08610">arXiv</a>
                    <p></p>
                    <p>Documents can be seen as a composition of semantic layers, and decomposing these layers helps on Domain Adaptation for Document Restoration.</p>
                  </td>
                </tr>

                <!-- GeoContrastNet -->
                <!-- You had a PNG inside a video tag. Keep it as an image unless you have a real mp4. -->
                <tr bgcolor="#ffffd0">
                  <td style="padding:16px;width:20%;vertical-align:middle">
                    <div class="one">
                      <img src="images/new_figure.png" alt="GeoContrastNet figure">
                    </div>
                  </td>
                  <td style="padding:8px;width:80%;vertical-align:middle">
                    <a href="https://arxiv.org/abs/2405.03104">
                      <span class="papertitle">GeoContrastNet: Contrastive Key-Value Edge Learning for Language-Agnostic Document Understanding</span>
                    </a>
                    <br>
                    <strong>Nil Biescas</strong>,
                    <a href="https://scholar.google.es/citations?user=92pWl-AAAAAJ&hl=es">Josep Lladós</a>,
                    <a href="https://scholar.google.co.in/citations?user=J-VlCNYAAAAJ&hl=en">Sanket Biswas</a>
                    <br>
                    <em>ICDAR</em>, 2025
                    <br>
                    <a href="https://github.com/NilBiescas/GeoContrastNet">project page</a> /
                    <a href="https://arxiv.org/abs/2405.03104">arXiv</a>
                    <p></p>
                    <p>
                      A method for structured document understanding without relying on language or OCR.
                      By combining geometric edge features and visual features in a two-stage graph attention framework, this model achieves strong performance on link prediction and entity recognition.
                      It captures spatial relations between text elements, learning key-value pairs in forms and table layouts in invoices.
                    </p>
                  </td>
                </tr>

                <!-- Document Digitallization -->
                <!-- You had a GIF inside a video tag. Just show the GIF as an image. -->
                <tr>
                  <td style="padding:16px;width:20%;vertical-align:middle">
                    <div class="one">
                      <img src="images/DD.gif" alt="Document Digitallization preview">
                    </div>
                  </td>
                  <td style="padding:8px;width:80%;vertical-align:middle">
                    <a href="https://mpilligua.github.io/Document-Digitallization.github.io/">
                      <span class="papertitle">Document Digitallization</span>
                    </a>
                    <br>
                    <strong>Nil Biescas</strong>,
                    <a href="https://mpilligua.github.io/">Maria Pilligua</a>,
                    <a href="https://www.linkedin.com/in/xavi-soto-350b51280/?originalSubdomain=es">Xavi Soto</a>,
                    <a href="https://nilbiescas.github.io/">Jordi Longaron</a>,
                    <a href="https://nilbiescas.github.io/">Laia Vilardell</a>
                    <br>
                    <em>Class Project</em>, 2024
                    <br>
                    <a href="https://mpilligua.github.io/Document-Digitallization.github.io/">project page</a>
                    <p></p>
                    <p>
                      Our work focuses on converting complex physical documents into an editable digital format.
                      The figure below outlines our pipeline, which separates textual and graphical elements before processing them.
                    </p>
                  </td>
                </tr>

              </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr>
                  <td style="padding:0px">
                    <br>
                    <p style="text-align:right;font-size:small;">
                      Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>.
                      <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website, so use the github code instead.
                      Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s
                      <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>

          </td>
        </tr>
      </tbody>
    </table>

    <!-- Play videos only on hover -->
    <script>
      document.querySelectorAll(".one.has-hover").forEach(box => {
        const v = box.querySelector("video");
        if (!v) return;

        box.addEventListener("mouseenter", () => v.play());
        box.addEventListener("mouseleave", () => {
          v.pause();
          v.currentTime = 0;
        });
      });
    </script>
  </body>
</html>
